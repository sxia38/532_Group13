{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Require to install sklearn\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn import decomposition\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick categories \n",
    "categories = ['alt.atheism', 'talk.religion.misc',\n",
    "              'comp.graphics', 'sci.space']\n",
    "# \n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "# Set training data and test data\n",
    "newsgroups_train = fetch_20newsgroups(subset = 'train', categories = categories, remove = remove)\n",
    "newsgroups_test = fetch_20newsgroups(subset = 'test', categories = categories, remove = remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2034,), (2034,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.filenames.shape, newsgroups_train.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2034\n"
     ]
    }
   ],
   "source": [
    "print(len(newsgroups_train.data))\n",
    "npArr = np.array(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "# print(\"\\n\".join(newsgroups_train.data[:2]))\n",
    "# npArr.shape\n",
    "# npArr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['faster',\n",
       " 'fastest',\n",
       " 'fastperftrig',\n",
       " 'fat',\n",
       " 'fatal',\n",
       " 'fatally',\n",
       " 'fate',\n",
       " 'fated',\n",
       " 'fates',\n",
       " 'father',\n",
       " 'fathers',\n",
       " 'fatigue',\n",
       " 'fatima',\n",
       " 'fatti',\n",
       " 'fatwa',\n",
       " 'fault',\n",
       " 'faults',\n",
       " 'faulty',\n",
       " 'favor',\n",
       " 'favorable',\n",
       " 'favored',\n",
       " 'favorite',\n",
       " 'favoritism',\n",
       " 'favors',\n",
       " 'favour',\n",
       " 'favourable',\n",
       " 'favourably',\n",
       " 'favoured',\n",
       " 'favouring',\n",
       " 'favourite',\n",
       " 'fax',\n",
       " 'fax_____________________________email______________________________',\n",
       " 'faxed',\n",
       " 'faxes',\n",
       " 'fbi',\n",
       " 'fbis',\n",
       " 'fbm',\n",
       " 'fbmquant',\n",
       " 'fbos',\n",
       " 'fcc',\n",
       " 'fd',\n",
       " 'fda',\n",
       " 'fear',\n",
       " 'feared',\n",
       " 'fearful',\n",
       " 'fearing',\n",
       " 'fears',\n",
       " 'feasability',\n",
       " 'feasibility',\n",
       " 'feasible',\n",
       " 'feast',\n",
       " 'feasts',\n",
       " 'feat',\n",
       " 'feature',\n",
       " 'featured',\n",
       " 'features',\n",
       " 'featurfes',\n",
       " 'featuring',\n",
       " 'feb',\n",
       " 'february',\n",
       " 'fed',\n",
       " 'federal',\n",
       " 'federation',\n",
       " 'feds',\n",
       " 'fee',\n",
       " 'feeble',\n",
       " 'feebleness',\n",
       " 'feed',\n",
       " 'feedback',\n",
       " 'feedbacks',\n",
       " 'feeding',\n",
       " 'feeds',\n",
       " 'feel',\n",
       " 'feeling',\n",
       " 'feelings',\n",
       " 'feels',\n",
       " 'feelt',\n",
       " 'fees',\n",
       " 'feestelijke',\n",
       " 'feet',\n",
       " 'feign',\n",
       " 'feild',\n",
       " 'feiner',\n",
       " 'fel',\n",
       " 'felder',\n",
       " 'feldman',\n",
       " 'fell',\n",
       " 'felled',\n",
       " 'fellow',\n",
       " 'fellowship',\n",
       " 'fellowships',\n",
       " 'felon',\n",
       " 'felt',\n",
       " 'feltham',\n",
       " 'fem',\n",
       " 'female',\n",
       " 'femine',\n",
       " 'feminism',\n",
       " 'feminist',\n",
       " 'feminists']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the CountVectorizer\n",
    "# to vectorize documents\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "train1 = vectorizer.fit_transform(npArr)\n",
    "# print(train1.todense())\n",
    "dictionary = vectorizer.get_feature_names()\n",
    "dictionary[10200:10300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to convert articles into document-term matrix\n",
    "# *****************************************************\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3ds',\n",
       " 'able',\n",
       " 'about',\n",
       " 'after',\n",
       " 'all',\n",
       " 'and',\n",
       " 'anyone',\n",
       " 'are',\n",
       " 'available',\n",
       " 'be',\n",
       " 'but',\n",
       " 'carefully',\n",
       " 'cel',\n",
       " 'default',\n",
       " 'does',\n",
       " 'explicitly',\n",
       " 'file',\n",
       " 'for',\n",
       " 'format',\n",
       " 'from',\n",
       " 'given',\n",
       " 'have',\n",
       " 'hi',\n",
       " 'if',\n",
       " 'in',\n",
       " 'information',\n",
       " 'is',\n",
       " 'it',\n",
       " 'know',\n",
       " 'like',\n",
       " 'manual',\n",
       " 'mapping',\n",
       " 'model',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'noticed',\n",
       " 'only',\n",
       " 'orientation',\n",
       " 'planes',\n",
       " 'position',\n",
       " 'positioned',\n",
       " 'positions',\n",
       " 'preserved',\n",
       " 'prj',\n",
       " 'read',\n",
       " 'reload',\n",
       " 'restarting',\n",
       " 'rule',\n",
       " 'rules',\n",
       " 'rych',\n",
       " 'said',\n",
       " 'save',\n",
       " 'saving',\n",
       " 'somewhere',\n",
       " 'stored',\n",
       " 'texture',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'they',\n",
       " 'this',\n",
       " 'to',\n",
       " 've',\n",
       " 'when',\n",
       " 'why',\n",
       " 'with',\n",
       " 'you',\n",
       " 'your']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the CountVectorizer\n",
    "# to vectorize documents\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "train1 = vectorizer.fit_transform(newsgroups_train.data[:1])\n",
    "train1.todense()\n",
    "dictionary = vectorizer.get_feature_names()\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "\n",
      "\n",
      "Seems to be, barring evidence to the contrary, that Koresh was simply\n",
      "another deranged fanatic who thought it neccessary to take a whole bunch of\n",
      "folks with him, children and all, to satisfy his delusional mania. Jim\n",
      "Jones, circa 1993.\n",
      "\n",
      "\n",
      "Nope - fruitcakes like Koresh have been demonstrating such evil corruption\n",
      "for centuries.\n",
      "\n",
      " >In article <1993Apr19.020359.26996@sq.sq.com>, msb@sq.sq.com (Mark Brader) \n",
      "\n",
      "MB>                                                             So the\n",
      "MB> 1970 figure seems unlikely to actually be anything but a perijove.\n",
      "\n",
      "JG>Sorry, _perijoves_...I'm not used to talking this language.\n",
      "\n",
      "Couldn't we just say periapsis or apoapsis?\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Print some topics \n",
    "print(\"\\n\".join(newsgroups_train.data[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['comp.graphics', 'talk.religion.misc', 'sci.space'],\n",
       "      dtype='<U18')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(newsgroups_train.target_names)[newsgroups_train.target[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 0, 2, 0, 2, 1, 2, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of topics \n",
    "num_tpoics = 6\n",
    "# Set the number of top words\n",
    "num_top_words = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Words, Stemming, Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amoungst']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import stop_words\n",
    "# Print some of the stop words:\n",
    "sorted(list(stop_words.ENGLISH_STOP_WORDS))[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming and Lemmatization\n",
    "Are these the same word?  \n",
    "organize, organizes, organizing  \n",
    "  \n",
    "Stemming and Lemmatization both generate the root form of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import natural langulage too-kit \n",
    "# Require to install NLTK\n",
    "import nltk\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannot use module nlkt in University Jupyter Notebook\n",
    "# Use sklearn instead:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = stem.WordNetLemmatizer()\n",
    "porter = stem.porter.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = ['feet', 'foot', 'foots', 'footing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foot', 'foot', 'foot', 'footing']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[wnl.lemmatize(word) for word in word_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feet', 'foot', 'foot', 'foot']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[porter.stem(word) for word in word_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try lemmatizing and stemming the following collections of words:  \n",
    "- fly, flies, flying  \n",
    "- organize, organizes, organizing  \n",
    "- universe, university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
